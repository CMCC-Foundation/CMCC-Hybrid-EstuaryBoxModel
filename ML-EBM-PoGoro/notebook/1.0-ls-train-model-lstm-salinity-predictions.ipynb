{"cells":[{"cell_type":"markdown","metadata":{"id":"qMZrbVLN22KT"},"source":["# Run experiment salinity forecasting with LSTM\n","\n","\n","---\n","\n","\n","The aim of this script is to build a LSTM model able to forecast the salinity at the estuary mouth."]},{"cell_type":"markdown","metadata":{"id":"JOohr7VS5Sop"},"source":["## Install & import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEPe4FyzlDkX"},"outputs":[],"source":["!pip install tensorflow\n","!pip install pandas\n","!pip install scikit-learn\n","!pip install keras-tuner --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbOdIUj45VdH"},"outputs":[],"source":["# Data Manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Data Visualization\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow / Keras\n","import keras_tuner as kt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import RootMeanSquaredError\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","# Other\n","import warnings\n","import os\n","from math import sqrt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuwWKgq_hwnk"},"outputs":[],"source":["warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"9XpXTrY5cWjr"},"source":["## Function definition"]},{"cell_type":"markdown","metadata":{"id":"djdIUDN2caJ3"},"source":["### Function to load the data and extract sequence from timeseries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhJFpo_AeKp4"},"outputs":[],"source":["def load_dataset(path_dataset):\n","  df = None\n","  if not os.path.isfile(path_dataset):\n","      print('Error! Invalid filename.')\n","  else:\n","      print(path_dataset + ' is a valid file.')\n","      df = pd.read_excel(path_dataset, index_col = 'Date')\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxwNXWSHcqGN"},"outputs":[],"source":["def df_to_X_y(df, features, output, n_features, window_size=1, step_ahead=0):\n","    X, y = [], []\n","    for i in range(len(df) - (window_size + step_ahead)):\n","        X.append(df.iloc[i:i + window_size][features].to_numpy())\n","        y.append(df.iloc[i + window_size: i + window_size + step_ahead][output].to_numpy())\n","    X = np.array(X)\n","    y = np.array(y)\n","    return np.reshape(X, (X.shape[0], window_size, n_features)), np.reshape(y, (y.shape[0], step_ahead))"]},{"cell_type":"markdown","metadata":{"id":"UkYdcJXbeLEl"},"source":["### Function to visualize the model results and compute metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4h0tZMkPeTMg"},"outputs":[],"source":["def plot_perfect_fit(obs, pred, plot_title, xy_lim, add_bound=False, bound=0):\n","  xy_line = np.linspace(0, xy_lim, xy_lim)\n","  legend_str = ['Observations', 'Perfect prediction']\n","\n","  plt.grid(visible=True)\n","  plt.scatter(obs, pred)\n","  plt.plot(xy_line, xy_line, 'k')\n","\n","  if add_bound:\n","      plt.plot(xy_line, xy_line + bound*xy_line/100,'r--')\n","      plt.plot(xy_line, xy_line - bound*xy_line/100,'r--')\n","      legend_str = ['Observations', 'Perfect prediction', str(bound) +'% of deviation']\n","\n","  plt.title(plot_title)\n","  plt.axis([0, xy_lim, 0, xy_lim])\n","  plt.legend(legend_str)\n","  plt.xlabel('True response (psu)')\n","  plt.ylabel('Predicted response (psu)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcgRqOZFaG0t"},"outputs":[],"source":["def plot_timeseries(obs, pred, plot_title, xy_lim):\n","  plt.grid(visible=True)\n","  plt.plot(obs)\n","  plt.plot(pred)\n","  plt.title(plot_title)\n","  plt.ylim([0, xy_lim])\n","\n","  plt.legend(['Observations', 'LSTM predictions'])\n","  plt.xlabel('Time steps')\n","  plt.ylabel('Sul (psu)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Emw-00V_lpiT"},"outputs":[],"source":["def compute_metrics(obs, pred):\n","  rmse=sqrt(mean_squared_error(obs,pred))\n","  mae=mean_absolute_error(obs,pred)\n","  r2 = r2_score(obs, pred)\n","  print('RMSE: {}\\nMAE: {}\\nR2: {}'.format(rmse, mae, r2))"]},{"cell_type":"markdown","metadata":{"id":"_FpCmMtD75iw"},"source":["### Function to define the search space of hyperparameters for LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ar44D_di8E0Y"},"outputs":[],"source":["def build_model(hp):\n","  model = Sequential(name='LSTM_Neural_Network')\n","\n","  model.add(LSTM(units=hp.Int(name='Units_LSTM_1', min_value=32, max_value=128, step=32),\n","                 input_shape=(window_size, n_features),\n","                 return_sequences=True))\n","  model.add(Dropout(hp.Float(name='dropout_factor_1', min_value=0.1, max_value=0.9, step=0.1)))\n","  model.add(LSTM(units=hp.Int(name='Units_LSTM_2', min_value=32, max_value=128, step=32)))\n","  model.add(Dropout(hp.Float(name='dropout_factor_2', min_value=0.1, max_value=0.9, step=0.1)))\n","\n","  # Define the optimizer learning rate as a hyperparameter.\n","  lr = hp.Float(name='learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n","\n","  model.compile(\n","      optimizer=Adam(learning_rate=lr),\n","      loss=['mean_squared_error'],\n","      metrics=[RootMeanSquaredError()],\n","      )\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"eqe_S3pRfbbR"},"source":["## Run the experiment"]},{"cell_type":"markdown","metadata":{"id":"Pxfuj60o8o9v"},"source":["### Define setting experiment\n","* *window_size*: the number of previous time steps should be considered into the sequence\n","* *n_features*: the number of features\n","* *step_ahead*: the number of steps ahead that the model should predict in sequence\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaubEexDjx3p"},"outputs":[],"source":["features = ['Qriver']\n","output = ['Sul']\n","window_size = 4\n","step_ahead = 7\n","n_features = len(features)\n","###################################\n","directory_network='network-trials\\\\'\n","project_name_network='lstm-qriver'\n","###################################\n","path_file = '..\\models\\LSTM\\only-qriver\\\\'\n","path_filename_results = path_file+str(window_size)+'DayInp_OutDay'+ str(step_ahead)+'.xlsx'\n","path_filename_trained_network = path_file+str(window_size)+'DayInp_OutDay'+ str(step_ahead)+'.h5'"]},{"cell_type":"markdown","metadata":{"id":"kBVkJp4O8Y-2"},"source":["### Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_6FYJedeuAd"},"outputs":[],"source":["df = load_dataset('..\\data\\processed\\input-features-sul.xlsx')\n","print('------------------------------------------------------------------------')\n","print('df shape: {}'.format(df.shape))\n","print('\\ndata types: \\n{}'.format(df.dtypes))\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHl9oVl-iw5x"},"outputs":[],"source":["dataset = df[features+output]\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"YB1xqBFB8hZ6"},"source":["### Scale the data in range [0,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7FbKNr6DDBV"},"outputs":[],"source":["scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_dataset = scaler.fit_transform(dataset)\n","scaler.fit_transform(dataset[output])\n","scaled_dataset = pd.DataFrame(scaled_dataset, columns=[features+output], index=dataset.index)\n","scaled_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebTezPDbcUwH"},"outputs":[],"source":["scaled_dataset.head(12)"]},{"cell_type":"markdown","source":["### Build sequence dataset"],"metadata":{"id":"LJRM81dG76DK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lc8upCoX8uKR"},"outputs":[],"source":["X,y = df_to_X_y(scaled_dataset,features, output, n_features, window_size, step_ahead)\n","print('Generated {} different sequence'.format(len(X)))\n","print('Sequence shape: {},{}'.format(X.shape,y.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4imTxwscUxT"},"outputs":[],"source":["X[1],y[1]"]},{"cell_type":"markdown","metadata":{"id":"HvirKrMQh9AI"},"source":["### Split into training, validation and test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I06ybOD8aKRN"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50dfSIyPdfPR"},"outputs":[],"source":["print('The training dataset has shape: {}, {}'.format(X_train.shape, y_train.shape))\n","print('The validation dataset has shape: {}, {}'.format(X_val.shape, y_val.shape))\n","print('The test dataset has shape: {}, {}'.format(X_test.shape, y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"Om8Ehsgf7lfE"},"source":["### LSTM development"]},{"cell_type":"markdown","metadata":{"id":"POd0ZGIp9A25"},"source":["#### Hyperparamters optimization procedure\n","* **MAX_TRIALS** Number of hyperparameter combinations that will be tested by the tuner\n","* **EXECUTION_PER_TRIAL** The number of models that should be built and fit for each trial. Different trials have different hyperparameter values. The executions within the same trial have the same hyperparameter values. The purpose of having multiple executions per trial is to reduce results variance and therefore be able to more accurately assess the performance of a model.\n","* **MAX_EPOCHS** Maximum number of epochs to train one model\n","* **MINI_BATCH** Size of subset of the dataset used to take another step in the learning process.Instead of waiting for the model to compute the whole dataset, we’re able to update its parameters more frequently. This reduces the risk of getting stuck at a local minimum, since different batches will be considered at each iteration, granting a robust convergence.\n","* **PATIENCE** - Number of epochs with no improvement after which training will be stopped."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdQB4-mq0QVJ"},"outputs":[],"source":["MAX_TRIALS = 75\n","EXECUTION_PER_TRIAL = 2\n","MAX_EPOCHS = 100\n","MINI_BATCH_SIZE = 16\n","PATIENCE = 5\n","\n","build_model(kt.HyperParameters())\n","tuner = kt.BayesianOptimization(\n","    hypermodel=build_model,\n","    objective=kt.Objective('val_loss', direction='min'),\n","    max_trials=MAX_TRIALS,\n","    executions_per_trial=EXECUTION_PER_TRIAL,\n","    distribution_strategy=tf.distribute.MirroredStrategy(),\n","    directory=directory_network,\n","    project_name=project_name_network,\n","    overwrite=True)\n","tuner.search_space_summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24AR_mqM0eEK"},"outputs":[],"source":["tuner.search(X_train, y_train,\n","             epochs=MAX_EPOCHS,\n","             batch_size=MINI_BATCH_SIZE,\n","             validation_data=(X_val, y_val),\n","             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                         patience=PATIENCE,\n","                                                         verbose=1,\n","                                                         restore_best_weights = True)])\n","print('The hyperparameter search is complete. The optimal hyperparameters are:')\n","tuner.get_best_hyperparameters()[0].values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eHGwjjDcFCNf"},"outputs":[],"source":["#%reload_ext tensorboard\n","#%tensorboard --logdir lstm-1StepAhead/lstm-1day-input"]},{"cell_type":"markdown","metadata":{"id":"jv9tp_vl9HMd"},"source":["#### Retraining the model with the best hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwaSfQQe-Mqk"},"outputs":[],"source":["X_train = np.vstack([X_train, X_val])\n","y_train = np.vstack([y_train, y_val])\n","X_train.shape, y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxxQBDk43fZ_"},"outputs":[],"source":["best_model = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n","training_history = best_model.fit(X_train, y_train,\n","                                  epochs=MAX_EPOCHS,\n","                                  batch_size=MINI_BATCH_SIZE,\n","                                  )\n","best_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYxq1172TKBN"},"outputs":[],"source":["y_train_pred = best_model.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOuloIaGTOmG"},"outputs":[],"source":["y_train = scaler.inverse_transform(np.reshape(y_train,(y_train.shape[0], step_ahead)))\n","y_train_pred = scaler.inverse_transform(y_train_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vF463QFTclv"},"outputs":[],"source":["y_train_df = pd.DataFrame(y_train, columns=['1_day', '2_day', '3_day', '4_day','5_day','6_day','7_day'])\n","y_train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNis3MeOTqvE"},"outputs":[],"source":["y_train_pred_df = pd.DataFrame(y_train_pred, columns=['1_day_pred', '2_day_pred','3_day_pred', '4_day_pred','5_day_pred', '6_day_pred', '7_day_pred'])\n","y_train_pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVxObJU08p7D"},"outputs":[],"source":["plot_perfect_fit(y_train_df['1_day'], y_train_pred_df['1_day_pred'], str(window_size) + ' previous input time steps', 30, True, 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKBAD1ER8p7E"},"outputs":[],"source":["plot_timeseries(y_train_df['1_day'], y_train_pred_df['1_day_pred'], str(window_size) + ' previous input time steps', 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sccKCfl78p7E"},"outputs":[],"source":["print('Train metrics')\n","compute_metrics(y_train_df['1_day'], y_train_pred_df['1_day_pred'])"]},{"cell_type":"markdown","metadata":{"id":"RrQBEo0P9NaG"},"source":["#### Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYR20rCJonE9"},"outputs":[],"source":["y_test_pred = best_model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcDmivLrpL5V"},"outputs":[],"source":["y_test = scaler.inverse_transform(np.reshape(y_test,(y_test.shape[0], step_ahead)))\n","y_test_pred = scaler.inverse_transform(y_test_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bj_nQgEqWHA0"},"outputs":[],"source":["y_test_df = pd.DataFrame(y_test, columns=['1_day', '2_day', '3_day', '4_day','5_day','6_day','7_day'])\n","y_test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMXWHvTgWoK8"},"outputs":[],"source":["y_test_pred_df = pd.DataFrame(y_test_pred, columns=['1_day_pred', '2_day_pred','3_day_pred', '4_day_pred','5_day_pred', '6_day_pred', '7_day_pred'])\n","y_test_pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mFKLjTopufH"},"outputs":[],"source":["plot_perfect_fit(y_test_df['1_day'], y_test_pred_df['1_day_pred'], str(window_size) + ' previous input time steps', 30, True, 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGNIauaJAZJU"},"outputs":[],"source":["plot_timeseries(y_test_df['1_day'], y_test_pred_df['1_day_pred'], str(window_size) + ' previous input time steps', 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDaLM98Lm45K"},"outputs":[],"source":["print('Test metrics')\n","compute_metrics(y_test_df['7_day'], y_test_pred_df['7_day_pred'])"]},{"cell_type":"markdown","metadata":{"id":"DMLvf07_qkOQ"},"source":["#### Save model and result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5baMV37Vodmw"},"outputs":[],"source":["data_train_pred=pd.concat([y_train_df,y_train_pred_df], axis=1)\n","data_train_pred.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WC7YZ70eZ18v"},"outputs":[],"source":["data_test_pred=pd.concat([y_test_df,y_test_pred_df], axis=1)\n","data_test_pred.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHJEaDlCZ9Ml"},"outputs":[],"source":["# create a excel writer object\n","with pd.ExcelWriter(path_filename_results) as writer:\n","  data_train_pred.to_excel(writer, sheet_name='Train')\n","  data_test_pred.to_excel(writer, sheet_name='Test')\n","\n","best_model.save(path_filename_trained_network)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["9XpXTrY5cWjr","djdIUDN2caJ3"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}